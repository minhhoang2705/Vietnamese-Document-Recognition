{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "au_1YTpU1jYh"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/release/2.5/doc/PaddleOCR_log.png\">\n",
    "\n",
    "<!--- @wandbcode{paddleocr} -->\n",
    "\n",
    "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxpWbuFh22dg"
   },
   "source": [
    "# Train and Debug Your OCR Models using PaddleOCR and Weights & Biases 🪄🐝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzGMBUra3ca6"
   },
   "source": [
    "This notebook talks about how you can use W&B with PaddleOCR to track training metrics and log model checkpoints for all your OCR needs!\n",
    "\n",
    "To use the W&B logger with the PaddleOCR training script just add the following at the bottom of your `config.yml` file.\n",
    "\n",
    "```\n",
    "wandb:\n",
    "    project: CoolOCR\n",
    "    entity: my_team\n",
    "    name: MyOCRModel\n",
    "```\n",
    "\n",
    "To log the metrics and checkpoints to W&B during training, the wandb client now has a direct integration into PaddleOCR. Using wandb for logging automatically adds all the metrics to your W&B dashboard, saves the models at every evaluation step, tags the best model and adds appropriate metadata for the saved model. An example dashboard is available [here](https://wandb.ai/manan-goel/text_detection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfhumXqi4sj5"
   },
   "source": [
    "## Setup 🖥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vngT8JS05Ufa"
   },
   "source": [
    "We begin by cloning the PaddleOCR library and installing the the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6L2Q10p1fQS"
   },
   "outputs": [],
   "source": [
    "# %%shell\n",
    "# git clone https://github.com/PaddlePaddle/PaddleOCR\n",
    "# pip install paddlepaddle-gpu pyclipper attrdict -qqq\n",
    "# cd PaddleOCR\n",
    "# pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "44t6h5I8maYN"
   },
   "outputs": [],
   "source": [
    "!pip install paddlepaddle-gpu pyclipper attrdict -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2_2JxV81aMba"
   },
   "outputs": [],
   "source": [
    "# !cp -r /content/PaddleOCR /content/drive/MyDrive/MyOCR-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7pRt2ULg5Fi"
   },
   "source": [
    "## Training 🏋️‍♀️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxQJbn3nhP-H"
   },
   "source": [
    "PaddleOCR comes with a huge array of pre-implemented models involved in the OCR pipeline. For this tutorial we will be looking at the text detection models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sr8MrZ6gh39P"
   },
   "source": [
    "### Downloading Training and Validation Data 💾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeCy96DWiLZP"
   },
   "source": [
    "We will use the ICDAR2015 dataset available [here](https://rrc.cvc.uab.es/?ch=4&com=downloads). The data has been logged as W&B artifacts for ease of use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gi8JJzGr_zM"
   },
   "source": [
    "### Downloading pretrained weights📈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nh7N3bxBsF99"
   },
   "outputs": [],
   "source": [
    "# !wget -P ./pretrain_models/ https://paddleocr.bj.bcebos.com/dygraph_v2.1/en_det/ResNet50_dcn_asf_synthtext_pretrained.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueIDJkCsIQ6N"
   },
   "source": [
    "### **Untar pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yk3ItxQuIvF5",
    "outputId": "36565b16-ad3f-4b78-de7e-5481f6261db4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR/pretrain_models\n"
     ]
    }
   ],
   "source": [
    "# cd ./pretrain_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNmALBuiIQjd"
   },
   "outputs": [],
   "source": [
    "# !tar -xf rec_r45_abinet_train.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qux1mPw7sTfV"
   },
   "source": [
    "### Setup the config.yml file to use W&B🛠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2Ueo-Q_sYOM"
   },
   "outputs": [],
   "source": [
    "# import yaml\n",
    "\n",
    "# with open(\"configs/det/det_r50_vd_sast_icdar15.yml\", \"r\") as f:\n",
    "#     config = yaml.safe_load(f)\n",
    "# config.update({\n",
    "#     'wandb': {\n",
    "#         'project': 'text_detection_2'\n",
    "#     }\n",
    "# })\n",
    "# config['Global'].update({\n",
    "#     'epoch_num': 5,\n",
    "#     'eval_batch_step': [0, 1000],\n",
    "#     'calc_metric_during_train': True\n",
    "# })\n",
    "\n",
    "# with open(\"configs/det/det_r50_db++_icdar15.yml\", \"w\") as f:\n",
    "#     yaml.safe_dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGj43o90RtGZ"
   },
   "source": [
    "### Train your Model 🏋️‍♀️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HRAwjx5dqqX"
   },
   "source": [
    "The following command will finetune the pretrained MobileNetV3 on the ICDAR2015 dataset while logging all training and validation metrics to a W&B dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lj403wqFc_0e",
    "outputId": "19d44d64-40c3-4c34-b03e-d1a3e316f9b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\miniconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\ProgramData\\miniconda3\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\training\\vn_paddleocr\\lib\\site-packages\\wget.py\", line 568, in <module>\n",
      "    filename = download(args[0], out=options.output)\n",
      "  File \"d:\\training\\vn_paddleocr\\lib\\site-packages\\wget.py\", line 526, in download\n",
      "    (tmpfile, headers) = ulib.urlretrieve(binurl, tmpfile, callback)\n",
      "  File \"C:\\ProgramData\\miniconda3\\lib\\urllib\\request.py\", line 241, in urlretrieve\n",
      "    with contextlib.closing(urlopen(url, data)) as fp:\n",
      "  File \"C:\\ProgramData\\miniconda3\\lib\\urllib\\request.py\", line 216, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"C:\\ProgramData\\miniconda3\\lib\\urllib\\request.py\", line 503, in open\n",
      "    req = Request(fullurl, data)\n",
      "  File \"C:\\ProgramData\\miniconda3\\lib\\urllib\\request.py\", line 322, in __init__\n",
      "    self.full_url = url\n",
      "  File \"C:\\ProgramData\\miniconda3\\lib\\urllib\\request.py\", line 348, in full_url\n",
      "    self._parse()\n",
      "  File \"C:\\ProgramData\\miniconda3\\lib\\urllib\\request.py\", line 377, in _parse\n",
      "    raise ValueError(\"unknown url type: %r\" % self.full_url)\n",
      "ValueError: unknown url type: '%27http%3A//nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2.19_amd64.deb%27'\n"
     ]
    }
   ],
   "source": [
    "!python -m wget 'http://nz2.archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2.19_amd64.deb'\n",
    "\n",
    "# !sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2.19_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apZ7OFBXdAn4",
    "outputId": "c318ee5b-c268-469b-f771-f269a7a8b98f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lmdb\n",
      "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting visualdl\n",
      "  Downloading visualdl-2.5.3-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (1.3.0.post5)\n",
      "Collecting bce-python-sdk (from visualdl)\n",
      "  Downloading bce_python_sdk-0.8.97-py3-none-any.whl (241 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.5/241.5 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flask>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from visualdl) (2.2.5)\n",
      "Collecting Flask-Babel>=3.0.0 (from visualdl)\n",
      "  Downloading flask_babel-4.0.0-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from visualdl) (1.23.5)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from visualdl) (9.4.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from visualdl) (3.20.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visualdl) (2.31.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from visualdl) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from visualdl) (3.7.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from visualdl) (1.5.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from visualdl) (23.2)\n",
      "Collecting rarfile (from visualdl)\n",
      "  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from visualdl) (5.9.5)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl) (2.1.2)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl) (8.1.7)\n",
      "Requirement already satisfied: Babel>=2.12 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl) (2.13.1)\n",
      "Requirement already satisfied: pytz>=2022.7 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl) (2023.3.post1)\n",
      "Collecting pycryptodome>=3.8.0 (from bce-python-sdk->visualdl)\n",
      "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from bce-python-sdk->visualdl) (0.18.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->visualdl) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->visualdl) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->visualdl) (4.44.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->visualdl) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->visualdl) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->visualdl) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=1.1.1->visualdl) (2.1.3)\n",
      "Installing collected packages: lmdb, rarfile, rapidfuzz, pycryptodome, bce-python-sdk, Flask-Babel, visualdl\n",
      "Successfully installed Flask-Babel-4.0.0 bce-python-sdk-0.8.97 lmdb-1.4.1 pycryptodome-3.19.0 rapidfuzz-3.5.2 rarfile-4.1 visualdl-2.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install lmdb rapidfuzz visualdl pyclipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lP6cVvdpst2l"
   },
   "outputs": [],
   "source": [
    "!python3 tools/train.py -c configs/det/det_r50_db++_icdar15.yml  \\\n",
    "         -o Global.pretrained_model=./pretrain_models/ResNet50_dcn_asf_synthtext_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "954peCPkf8Er"
   },
   "source": [
    "### Evaluate text detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-u7_Fc9a_1Y"
   },
   "outputs": [],
   "source": [
    "!python3 tools/eval.py -c configs/det/det_r50_db++_icdar15.yml  -o Global.checkpoints=\"./artifacts/model-txx4644w:v6/model_ckpt\" PostProcess.box_thresh=0.1 PostProcess.unclip_ratio=1.5 Eval.dataset.data_dir='./train_data/data_ocr_doc/test_dir' Eval.dataset.label_file_list='./train_data/data_ocr_doc/test_label.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NelDbWef0vJ"
   },
   "source": [
    "### Perform detection on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paKmjpY7d3_0"
   },
   "outputs": [],
   "source": [
    "!python3 tools/infer_det.py -c configs/det/det_r50_db++_icdar15.yml -o Global.infer_img='./doc/imgs_en/' Global.pretrained_model=\"./output/det_r50_icdar15/latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8_Wh24ZFQgm"
   },
   "source": [
    "### Train recognition model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agjYQ29jTeT7"
   },
   "source": [
    "### **Downloading pretrained model for Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDG0FUBKTn3S",
    "outputId": "d93077be-2953-4c32-f916-67e6e3e63555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-31 02:42:30--  https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_train.tar\n",
      "Resolving paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)... 103.235.46.61, 2409:8c04:1001:1002:0:ff:b001:368a\n",
      "Connecting to paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)|103.235.46.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 190740480 (182M) [application/x-tar]\n",
      "Saving to: ‘./pretrain_models/en_PP-OCRv4_rec_train.tar’\n",
      "\n",
      "en_PP-OCRv4_rec_tra 100%[===================>] 181.90M  40.6MB/s    in 5.1s    \n",
      "\n",
      "2023-10-31 02:42:35 (35.4 MB/s) - ‘./pretrain_models/en_PP-OCRv4_rec_train.tar’ saved [190740480/190740480]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ./pretrain_models/ https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_train.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxGy5QFvTspu"
   },
   "source": [
    "**Untar pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISxeC8ylZTZi",
    "outputId": "843b7133-502a-4cc7-c9e7-a7b0b64c77d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR/pretrain_models\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/PaddleOCR/pretrain_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1Ad5Xt-Tyd4"
   },
   "outputs": [],
   "source": [
    "!tar -xf en_PP-OCRv4_rec_train.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rb05B7lUBXv",
    "outputId": "ad675718-e7ad-4cb7-d6e0-d8c6c1ee22e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/PaddleOCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWhxE3XLA7wt"
   },
   "source": [
    "### Train recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ggLdoX0q8P9S"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"configs/rec/rec_r34_vd_none_bilstm_ctc.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config[\"Optimizer\"].update({\"regularizer\": {\"factor\": 1e-4, \"name\": \"L2\"}})\n",
    "\n",
    "config[\"Optimizer\"].update({\"lr\": {\"learning_rate\": 5e-5}})\n",
    "\n",
    "config[\"Train\"].update(\n",
    "    {\n",
    "        \"loader\": {\n",
    "            \"batch_size_per_card\": 32,\n",
    "            \"drop_last\": True,\n",
    "            \"num_workers\": 8,\n",
    "            \"shuffle\": True,\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "config[\"Eval\"].update(\n",
    "    {\n",
    "        \"loader\": {\n",
    "            \"batch_size_per_card\": 8,\n",
    "            \"drop_last\": False,\n",
    "            \"num_workers\": 6,\n",
    "            \"shuffle\": False,\n",
    "        }\n",
    "    }\n",
    ")\n",
    "# config['Optimizer']['lr']['learning_rate'] = 5e-5\n",
    "\n",
    "# config['Train']['loader']['batch_size_per_card'] = 16\n",
    "# config['Eval']['loader']['batch_size_per_card'] = 8\n",
    "\n",
    "# modified_config_path = './configs/rec/rec_r34_vd_none_bilstm_ctc_vie_modified.yml'\n",
    "\n",
    "# with open(modified_config_path, 'w') as file:\n",
    "#   yaml.dump(config, file)\n",
    "with open(\"configs/rec/rec_r34_vd_none_bilstm_ctc.yml\", \"w\") as f:\n",
    "    yaml.safe_dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skTOesHOFT0C",
    "outputId": "987daedc-aa54-4ffc-e496-8a5afc4a97f6"
   },
   "outputs": [],
   "source": [
    "!python tools/train.py -c configs/rec/rec_r34_vd_none_bilstm_ctc.yml \n",
    "                        # -o Global.pretrained_model='./pretrain_models/rec_r34_vd_none_bilstm_ctc_v2.0_train/best_accuracy' \\\n",
    "                        # Global.checkpoints=./output/rec/r34_vd_none_bilstm_ctc_vie_v2/latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIG5YfcIKxaf"
   },
   "outputs": [],
   "source": [
    "!python3 tools/train.py -c configs/rec/PP-OCRv4/en_PP-OCRv4_vie_rec.yml \\\n",
    "                        -o Global.pretrained_model=./pretrain_models/en_PP-OCRv4_rec_train/best_accuracy \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0C3MUkzUDy-q",
    "outputId": "4b5a4037-384e-46af-9b59-aa1ba6bfbe89"
   },
   "outputs": [],
   "source": [
    "# GPU evaluation\n",
    "!python3 tools/eval.py -c configs/rec/rec_r34_vd_none_bilstm_ctc.yml \\\n",
    "                       -o Global.pretrained_model='./output/rec/r34_vd_none_bilstm_ctc_vie/latest' \\\n",
    "                       Eval.dataset.data_dir='./train_data/2nd_phase/rec_data/Vietnamese' \\\n",
    "                       Eval.dataset.label_file_list='./train_data/2nd_phase/rec_data/output.txt' \\\n",
    "                      #  Eval.dataset.RecResizeImg.image_shape = [3, 32, 1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePZNPl5Dikk0"
   },
   "source": [
    "### **Make predictions with model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XrzKKDd2FHeI",
    "outputId": "d88be960-c89f-49d4-eace-e7bb70c70ec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/11/27 04:07:12] ppocr INFO: Architecture : \n",
      "[2023/11/27 04:07:12] ppocr INFO:     Backbone : \n",
      "[2023/11/27 04:07:12] ppocr INFO:         layers : 34\n",
      "[2023/11/27 04:07:12] ppocr INFO:         name : ResNet\n",
      "[2023/11/27 04:07:12] ppocr INFO:     Head : \n",
      "[2023/11/27 04:07:12] ppocr INFO:         fc_decay : 0\n",
      "[2023/11/27 04:07:12] ppocr INFO:         name : CTCHead\n",
      "[2023/11/27 04:07:12] ppocr INFO:     Neck : \n",
      "[2023/11/27 04:07:12] ppocr INFO:         encoder_type : rnn\n",
      "[2023/11/27 04:07:12] ppocr INFO:         hidden_size : 256\n",
      "[2023/11/27 04:07:12] ppocr INFO:         name : SequenceEncoder\n",
      "[2023/11/27 04:07:12] ppocr INFO:     Transform : None\n",
      "[2023/11/27 04:07:12] ppocr INFO:     algorithm : CRNN\n",
      "[2023/11/27 04:07:12] ppocr INFO:     model_type : rec\n",
      "[2023/11/27 04:07:12] ppocr INFO: Eval : \n",
      "[2023/11/27 04:07:12] ppocr INFO:     dataset : \n",
      "[2023/11/27 04:07:12] ppocr INFO:         data_dir : ./train_data/2nd_phase/rec_data/Vietnamese\n",
      "[2023/11/27 04:07:12] ppocr INFO:         label_file_list : ./train_data/2nd_phase/rec_data/output.txt\n",
      "[2023/11/27 04:07:12] ppocr INFO:         name : SimpleDataSet\n",
      "[2023/11/27 04:07:12] ppocr INFO:         transforms : \n",
      "[2023/11/27 04:07:12] ppocr INFO:             DecodeImage : \n",
      "[2023/11/27 04:07:12] ppocr INFO:                 channel_first : False\n",
      "[2023/11/27 04:07:12] ppocr INFO:                 img_mode : BGR\n",
      "[2023/11/27 04:07:12] ppocr INFO:             CTCLabelEncode : None\n",
      "[2023/11/27 04:07:12] ppocr INFO:             RecResizeImg : \n",
      "[2023/11/27 04:07:12] ppocr INFO:                 image_shape : [3, 32, 1024]\n",
      "[2023/11/27 04:07:12] ppocr INFO:             KeepKeys : \n",
      "[2023/11/27 04:07:12] ppocr INFO:                 keep_keys : ['image', 'label', 'length']\n",
      "[2023/11/27 04:07:12] ppocr INFO:     loader : \n",
      "[2023/11/27 04:07:12] ppocr INFO:         batch_size_per_card : 16\n",
      "[2023/11/27 04:07:12] ppocr INFO:         drop_last : False\n",
      "[2023/11/27 04:07:12] ppocr INFO:         num_workers : 6\n",
      "[2023/11/27 04:07:12] ppocr INFO:         shuffle : False\n",
      "[2023/11/27 04:07:12] ppocr INFO: Global : \n",
      "[2023/11/27 04:07:12] ppocr INFO:     cal_metric_during_train : True\n",
      "[2023/11/27 04:07:12] ppocr INFO:     character_dict_path : ./ppocr/utils/dict/custom.txt\n",
      "[2023/11/27 04:07:12] ppocr INFO:     checkpoints : ./output/rec/r34_vd_none_bilstm_ctc_vie_v2/latest\n",
      "[2023/11/27 04:07:12] ppocr INFO:     distributed : False\n",
      "[2023/11/27 04:07:12] ppocr INFO:     epoch_num : 500\n",
      "[2023/11/27 04:07:12] ppocr INFO:     eval_batch_step : [0, 500]\n",
      "[2023/11/27 04:07:12] ppocr INFO:     infer_img : train_data/2nd_phase/rec_data/double_word_data/argument_data_4/978.jpg\n",
      "[2023/11/27 04:07:12] ppocr INFO:     infer_mode : False\n",
      "[2023/11/27 04:07:12] ppocr INFO:     log_smooth_window : 20\n",
      "[2023/11/27 04:07:12] ppocr INFO:     max_text_length : 1000\n",
      "[2023/11/27 04:07:12] ppocr INFO:     pretrained_model : ./output/rec/r34_vd_none_bilstm_ctc_vie_v2/latest\n",
      "[2023/11/27 04:07:12] ppocr INFO:     print_batch_step : 10\n",
      "[2023/11/27 04:07:12] ppocr INFO:     save_epoch_step : 5\n",
      "[2023/11/27 04:07:12] ppocr INFO:     save_inference_dir : None\n",
      "[2023/11/27 04:07:12] ppocr INFO:     save_model_dir : ./output/rec/r34_vd_none_bilstm_ctc_vie_v2/\n",
      "[2023/11/27 04:07:12] ppocr INFO:     save_res_path : ./output/rec/predicts_r34_vd_none_bilstm_ctc.txt\n",
      "[2023/11/27 04:07:12] ppocr INFO:     use_gpu : True\n",
      "[2023/11/27 04:07:12] ppocr INFO:     use_space_char : True\n",
      "[2023/11/27 04:07:12] ppocr INFO:     use_visualdl : False\n",
      "[2023/11/27 04:07:12] ppocr INFO: Loss : \n",
      "[2023/11/27 04:07:12] ppocr INFO:     name : CTCLoss\n",
      "[2023/11/27 04:07:12] ppocr INFO: Metric : \n",
      "[2023/11/27 04:07:12] ppocr INFO:     main_indicator : acc\n",
      "[2023/11/27 04:07:12] ppocr INFO:     name : RecMetric\n",
      "[2023/11/27 04:07:12] ppocr INFO: Optimizer : \n",
      "[2023/11/27 04:07:12] ppocr INFO:     beta1 : 0.9\n",
      "[2023/11/27 04:07:12] ppocr INFO:     beta2 : 0.999\n",
      "[2023/11/27 04:07:12] ppocr INFO:     lr : \n",
      "[2023/11/27 04:07:12] ppocr INFO:         learning_rate : 0.0005\n",
      "[2023/11/27 04:07:12] ppocr INFO:     name : Adam\n",
      "[2023/11/27 04:07:12] ppocr INFO:     regularizer : \n",
      "[2023/11/27 04:07:12] ppocr INFO:         factor : 0\n",
      "[2023/11/27 04:07:12] ppocr INFO:         name : L2\n",
      "[2023/11/27 04:07:12] ppocr INFO: PostProcess : \n",
      "[2023/11/27 04:07:12] ppocr INFO:     name : CTCLabelDecode\n",
      "[2023/11/27 04:07:12] ppocr INFO: Train : \n",
      "[2023/11/27 04:07:12] ppocr INFO:     dataset : \n",
      "[2023/11/27 04:07:12] ppocr INFO:         data_dir : ./train_data/2nd_phase/rec_data/double_word_data\n",
      "[2023/11/27 04:07:12] ppocr INFO:         label_file_list : ./train_data/2nd_phase/rec_data/train_data.txt\n",
      "[2023/11/27 04:07:12] ppocr INFO:         name : SimpleDataSet\n",
      "[2023/11/27 04:07:12] ppocr INFO:         transforms : \n",
      "[2023/11/27 04:07:12] ppocr INFO:             DecodeImage : \n",
      "[2023/11/27 04:07:12] ppocr INFO:                 channel_first : False\n",
      "[2023/11/27 04:07:12] ppocr INFO:                 img_mode : BGR\n",
      "[2023/11/27 04:07:12] ppocr INFO:             CTCLabelEncode : None\n",
      "[2023/11/27 04:07:12] ppocr INFO:             RecResizeImg : \n",
      "[2023/11/27 04:07:12] ppocr INFO:                 image_shape : [3, 32, 1024]\n",
      "[2023/11/27 04:07:12] ppocr INFO:             KeepKeys : \n",
      "[2023/11/27 04:07:12] ppocr INFO:                 keep_keys : ['image', 'label', 'length']\n",
      "[2023/11/27 04:07:12] ppocr INFO:     loader : \n",
      "[2023/11/27 04:07:12] ppocr INFO:         batch_size_per_card : 32\n",
      "[2023/11/27 04:07:12] ppocr INFO:         drop_last : True\n",
      "[2023/11/27 04:07:12] ppocr INFO:         num_workers : 8\n",
      "[2023/11/27 04:07:12] ppocr INFO:         shuffle : True\n",
      "[2023/11/27 04:07:12] ppocr INFO: profiler_options : None\n",
      "[2023/11/27 04:07:12] ppocr INFO: train with paddle 2.5.2 and device Place(gpu:0)\n",
      "W1127 04:07:12.324527 32855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.0, Runtime API Version: 11.8\n",
      "W1127 04:07:12.325663 32855 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\n",
      "[2023/11/27 04:07:14] ppocr INFO: resume from ./output/rec/r34_vd_none_bilstm_ctc_vie_v2/latest\n",
      "[2023/11/27 04:07:14] ppocr INFO: infer_img: train_data/2nd_phase/rec_data/double_word_data/argument_data_4/978.jpg\n",
      "[2023/11/27 04:07:16] ppocr INFO: \t result: một được thêm gian non khi nở chăm chim hết Hu mẹ\t0.9876344799995422\n",
      "[2023/11/27 04:07:16] ppocr INFO: success!\n"
     ]
    }
   ],
   "source": [
    "# The configuration file used for prediction must match the training\n",
    "!python3 tools/infer_rec.py -c configs/rec/rec_r34_vd_none_bilstm_ctc.yml -o Global.pretrained_model='./output/rec/r34_vd_none_bilstm_ctc_vie_v2/latest' Global.infer_img=train_data/2nd_phase/rec_data/double_word_data/argument_data_4/978.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwoVteV1W4u1"
   },
   "outputs": [],
   "source": [
    "!python3 tools/infer_rec.py -c configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml -o Global.pretrained_model='./output/v3_en_mobile/latest' Global.infer_img=train_data/rec_data_final/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbtFW0O8iukg"
   },
   "source": [
    "### **Export model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDAa0BmPiwvR",
    "outputId": "9fa7b091-d605-4578-cb33-0604199783ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1031 06:06:17.083590 50008 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.0, Runtime API Version: 11.8\n",
      "W1031 06:06:17.084780 50008 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\n",
      "[2023/10/31 06:06:19] ppocr INFO: resume from ./output/rec/r34_vd_none_bilstm_ctc_vie/latest\n",
      "I1031 06:06:27.363452 50008 interpretercore.cc:237] New Executor is Running.\n",
      "[2023/10/31 06:06:34] ppocr INFO: inference model is saved to ./inference/crnn_vie/inference\n"
     ]
    }
   ],
   "source": [
    "!python3 tools/export_model.py -c configs/rec/rec_r34_vd_none_bilstm_ctc.yml -o Global.pretrained_model=\"./output/rec/r34_vd_none_bilstm_ctc_vie/best_accuracy\"  Global.save_inference_dir=./inference/crnn_vie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7wTMpd6Q29Y"
   },
   "outputs": [],
   "source": [
    "!python3 tools/export_model.py -c configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml -o Global.pretrained_model=\"./output/v3_en_mobile/best_accuracy\" Global.save_inference_dir=./inference/en_rec_pprocr_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuFvkPZlsg5Y"
   },
   "outputs": [],
   "source": [
    "!python3 tools/infer/predict_det.py \\\n",
    "            --image_dir=\"./train_data/61bb9a7943343e03bb9fcd1b_documents-product-template-software.png\" \\\n",
    "            --det_model_dir=\"./inference/DB++/\" \\\n",
    "            --det_algorithm=\"DB++\"  \\\n",
    "            --det_db_box_thresh=0.1 \\\n",
    "            --det_db_thresh=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwsQ6c1GfzY6"
   },
   "outputs": [],
   "source": [
    "!python3 tools/infer/predict_rec.py --image_dir=\"./train_data/kolapa_challange/images/10/\" \\\n",
    "                                    --rec_model_dir=\"./inference/crnn_vie/\" \\\n",
    "                                    --rec_image_shape=\"3,32,100\" \\\n",
    "                                    --rec_char_dict_path=\"./ppocr/utils/dict/custom.txt\" \\\n",
    "                                    --use_space_char=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGCzoVVkSuNc",
    "outputId": "0459a8ef-c166-4561-9fbf-f22dfe68ad70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/10/13 01:42:02] ppocr INFO: In PP-OCRv3, rec_image_shape parameter defaults to '3, 48, 320', if you are using recognition model with PP-OCRv2 or an older version, please set --rec_image_shape='3,32,320\n",
      "[2023/10/13 01:42:04] ppocr INFO: Predicts of ./train_data/rec_data_final/20230420_000001.jpg:('\"IieCDESs\"', 0.7385871410369873)\n"
     ]
    }
   ],
   "source": [
    "!python3 tools/infer/predict_rec.py --image_dir=\"./train_data/rec_data_final/20230420_000001.jpg\"  \\\n",
    "                                    --rec_model_dir=\"./inference/en_rec_pprocr_v3/\"  \\\n",
    "                                    --rec_image_shape=\"3,48,320\"  \\\n",
    "                                    --rec_char_dict_path=\"./ppocr/utils/en_dict.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozRK6rnNmLRy"
   },
   "source": [
    "### Predict System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtJZnI3RmN1G",
    "outputId": "183b5785-3087-46d3-8796-0a37b83fd349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/11/30 16:11:07] ppocr INFO: In PP-OCRv3, rec_image_shape parameter defaults to '3, 48, 320', if you are using recognition model with PP-OCRv2 or an older version, please set --rec_image_shape='3,32,320\n",
      "[2023/11/30 16:11:09] ppocr DEBUG: dt_boxes num : 28, elapsed : 2.495605230331421\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: rec_res num  : 28, elapsed : 1.397994041442871\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: 0  Predict time of D:\\training\\PaddleOCR\\page-1.png: 3.950s\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"HAI ĐỨA TR - THẠCH LAM\", 0.971\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"Phân tích tâm trạng hai chị em Liên khi đọi tàu\", 0.981\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"Một truyện ngn hay theo quan niệm truyền thống phải có cốt truyện đc biệt được tạo ra\", 0.992\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"bởi nhng tình huống éo le đy kịch tính. Không đi theo lối mòn đó, truyện -\"Hai đứa tr/ in\", 0.980\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: trOng tp Nãng trOng Vườn Của Thạch Lam Chỉ là mỘt Chuyện tâm tình nh nhẹ nhưng, 0.977\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"không vì thế mà ta có th d dàng quên được tâm trạng thức đợi tàu của chị em Liên. Ngày, 0.995\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"lại ngày khi đêm về khuya, chuyến tàu từ Hà Nội về đi qua phố huyện vy mà hai chị em\", 0.990\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"Liên vn khc khoải thao thức và nhn lại, hồi hộp chờ đợi được nhìn nó với bao vui buồn\", 0.992\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: và hi Vọng. Thạch Lam là một nhà văn lãng mạn tiêu biu của nhóm T Lc Văn Đoàn., 0.989\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"Sáng tác của ông thiên về phản ánh hiện thc đời sống của tng lớp người nghèo  các phố, 0.986\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"huyện nh và làng quê nghèo. Đọc nhng truyện ngn -Gió lạnh đu mùa, (Dưới bóng, 0.992\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"hoàng lan/. . . nhL là truyện ngn Hai đứa tr2 ta d dàng nhn ra mộL lối viếL thL tinh tế\", 0.973\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: cùng tm lòng rt mc nhạy cảm và nhân hu. đ đó, ông chủ yếu đi sâu th hiện nhng xúc, 0.987\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: cảm mong manh mơ hồ trong thế giới nội tâm nhân vt vì thế truyện ngn của ông còn được\", 0.996\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: ví như một bài thơ tr tình đượm buồn:, 0.978\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"Câu truyện được bt đu với nhng xao động trong tâm hồn hai đứa tr khi nghe tiếng trống\", 0.992\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: thu không gOi chiêu Vê trên ph huyện. Tiêp đó, màn đêm bung Xung, bóng ti -ngp đây, 0.985\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"dn đôi mt Liên. Đêm tối như ôm trùm lên tt cả phố huyện và càng dày đc mênh mông\", 0.994\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"hơn khi nhà văn đim vào đó nhng hột sáng9. (qung sáng\" leo lét, lờ mờ và một chm\", 0.972\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"lửa nh lơ lửng trôi đi trOng đêm. . . Ni bt lên gia thê giới đây bóng tôi và s tàn tạa của, 0.986\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"cảnh vt: chiều tàn, chợ tàn, chng tàn. .. là cảnh sống lam l qun quanh của nhng đứa tr, 0.983\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"nht rác, mẹ con chị Tí với gánh hàng 1ước ế m, gia đình bác xm, bà cụ Thi điên và hai, 0.989\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: Chị em Liên và. An Với gian hàng tạp hoá cồm ci, lèo tèo, XƠ Xác. CuộC sng Của hai chị em, 0.960\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"tht lay lt, t nhạt, ngày cng như đêm cứ lp đi lp lại tht đơn điệu và buồn chán. Hai em\", 0.996\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"như hai cái mm non mọc trên mảnh đt cn ci, bạc phếch.\", 0.993\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"Nhưng con người t muôn đời nay luôn luôn sông trong khao khát và hi vọng nhng gì tươi\", 0.990\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: \"sáng hơn dù trong bât cú hoàn cảnh nào. Sống gia phô huyện nghèo đy bóng tối nhưng\", 0.989\n",
      "[2023/11/30 16:11:11] ppocr DEBUG: Chị em Liên Cửng như Chừng ây người nơi phô huyện Vn luôn mOng đợi một cái gì tươi\", 0.974\n",
      "[2023/11/30 16:11:12] ppocr DEBUG: The visualized image saved in ./inference_results\\page-1.png\n",
      "[2023/11/30 16:11:12] ppocr INFO: The predict total time is 4.948222637176514\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/infer/predict_system.py \\\n",
    "           --image_dir=\"D:\\training\\PaddleOCR\\page-1.png\"  \\\n",
    "           --use_gpu=True \\\n",
    "           --det_algorithm=\"DB++\"  \\\n",
    "           --det_model_dir=\"./inference/DB++/\"  \\\n",
    "           --det_db_thresh=0.1  \\\n",
    "           --det_db_box_thresh=0.1  \\\n",
    "           --det_db_unclip_ratio=2.5  \\\n",
    "           --rec_model_dir=\"./inference/crnn_vie/\"  \\\n",
    "           --rec_algorithm=\"CRNN\"  \\\n",
    "           --rec_image_shape=\"3,32,100\"  \\\n",
    "           --rec_char_dict_path=\"./ppocr/utils/dict/custom.txt\" \\\n",
    "           --vis_font_path=\"./ppocr/utils/font-times-new-roman.ttf\" \\\n",
    "           --use_space_char=True\n",
    "          #  --drop_score=0.5  \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zs7HFK3Arw8u"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97vRa7cEjCnh"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def evaluate_detection(model_path, data_test_path, label_test_path):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    model_path (str): Path lead to model checkpoint\n",
    "    data_test_path (str): Path lead to test data directory\n",
    "    label_test_path (str): Path lead to test label text file\n",
    "  \"\"\"\n",
    "  command = \"python3 tools/eval.py\"\n",
    "  det_config = \"configs/det/det_r50_db++_icdar15.yml\"\n",
    "  cmd_string = f\"{command} -c {det_config} -o Global.checkpoints='{model_path}' Eval.dataset.data_dir='{data_test_path}' Eval.dataset.label_file_list='{label_test_path}'\"\n",
    "  result = subprocess.run(cmd_string , shell= True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "  if result.returncode == 0:\n",
    "    print(\"Detection Model Evaluation Result:\", end='\\n')\n",
    "    print(result.stdout)\n",
    "  else:\n",
    "    print(\"Error in Detection Model Evaluation:\", end='\\n')\n",
    "    print(result.stderr)\n",
    "\n",
    "def evaluate_recognition(model_path, data_test_path, label_test_path):\n",
    "  command = \"python3 tools/eval.py\"\n",
    "  rec_config = \"configs/rec/rec_r50_fpn_srn.yml\"\n",
    "  cmd_string = f\"{command} -c {rec_config} -o Global.checkpoints='{model_path}' Eval.dataset.data_dir='{data_test_path}' Eval.dataset.label_file_list='{label_test_path}'\"\n",
    "  result = subprocess.run(cmd_string, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "  if result.returncode == 0:\n",
    "    print(\"Recognition Model Evaluation Result:\", end='\\n')\n",
    "    print(result.stdout)\n",
    "  else:\n",
    "    print(\"Error in Recognition Model Evaluation:\", end='\\n')\n",
    "    print(result.stderr)\n",
    "\n",
    "model_path = \"./artifacts/model-txx4644w:v6/model_ckpt\"\n",
    "data_test_path = \"./train_data/data_ocr_doc/\"\n",
    "label_test_path = \"./train_data/label_final4eval/det_label_final.txt\"\n",
    "rec_model_path = \"./output/rec/srn_new/best_accuracy\"\n",
    "rec_data_test_path = \"./train_data/rec_data_final/\"\n",
    "rec_label_test_path = \"./train_data/label_final4eval/rec_label_eval.txt\"\n",
    "\n",
    "# evaluate_detection(model_path, data_test_path, label_test_path)\n",
    "evaluate_recognition(rec_model_path, rec_data_test_path, rec_label_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ercNZ0aul3uy"
   },
   "outputs": [],
   "source": [
    "!python3 tools/eval.py -c configs/det/det_r50_db++_icdar15.yml -o Global.checkpoints='./artifacts/model-txx4644w:v6/model_ckpt' Eval.dataset.data_dir='./train_data/data_ocr_doc/' Eval.dataset.label_file_list='./train_data/label_final4eval/det_label_final.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8YnNN4ojDFI"
   },
   "source": [
    "### Evaluate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZUV6pZKpP2v",
    "outputId": "50bf7875-b7f8-4661-b722-80b2cde3b1a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Model Evaluation:\n",
      "b'W1005 09:22:15.793431 10536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.0, Runtime API Version: 11.8\\nW1005 09:22:15.794628 10536 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\\n\\reval model::   0%|          | 0/32 [00:00<?, ?it/s]Exception in thread Thread-2 (_thread_loop):\\nTraceback (most recent call last):\\n  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\\nTraceback (most recent call last):\\n  File \"/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR/tools/eval.py\", line 146, in <module>\\n    self.run()\\n  File \"/usr/lib/python3.10/threading.py\", line 953, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/io/dataloader/dataloader_iter.py\", line 604, in _thread_loop\\n    batch = self._get_data()\\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/io/dataloader/dataloader_iter.py\", line 752, in _get_data\\n    batch.reraise()\\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/io/dataloader/worker.py\", line 178, in reraise\\n    raise self.exc_type(msg)\\nRecursionError: DataLoader worker(1) caught RecursionError with message:\\nTraceback (most recent call last):\\n  File \"/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR/ppocr/data/simple_dataset.py\", line 155, in __getitem__\\n    raise Exception(\"{} does not exist!\".format(img_path))\\nException: ./train_data/rec_data_final/20230420_000004.jpg, does not exist!\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/io/dataloader/worker.py\", line 363, in _worker_loop\\n    batch = fetcher.fetch(indices)\\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/io/dataloader/fetcher.py\", line 78, in fetch\\n    data.append(self.dataset[idx])\\n  File \"/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR/ppocr/data/simple_dataset.py\", line 170, in __getitem__\\n    return self.__getitem__(rnd_idx)\\n  File \"/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR/ppocr/data/simple_dataset.py\", line 170, in __getitem__\\n    return self.__getitem__(rnd_idx)\\n  File \"/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR/ppocr/data/simple_dataset.py\", line 170, in __getitem__\\n    return self.__getitem__(rnd_idx)\\n  [Previous line repeated 968 more times]\\n  File \"/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR/ppocr/data/simple_dataset.py\", line 162, in __getitem__\\n    self.logger.error(\\n  File \"/usr/lib/python3.10/logging/__init__.py\", line 1506, in error\\n    self._log(ERROR, msg, args, **kwargs)\\n  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\\n    self.handle(record)\\n  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\\n    self.callHandlers(record)\\n  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\\n    hdlr.handle(record)\\n  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\\n    self.emit(record)\\n  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\\n    msg = self.format(record)\\n  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\\n    return fmt.format(record)\\n  File \"/usr/lib/python3.10/logging/__init__.py\", line 679, in format\\n    if self.usesTime():\\n  File \"/usr/lib/python3.10/logging/__init__.py\", line 647, in usesTime\\n    return self._style.usesTime()\\n  File \"/usr/lib/python3.10/logging/__init__.py\", line 424, in usesTime\\n    return self._fmt.find(self.asctime_search) >= 0\\nRecursionError: maximum recursion depth exceeded while calling a Python object\\n\\n    main()\\n  File \"/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR/tools/eval.py\", line 136, in main\\n    metric = program.eval(model, valid_dataloader, post_process_class,\\n  File \"/content/drive/.shortcut-targets-by-id/1cSshdYUZTZkYNN2CZQLwNyiRaY41sdpH/PaddleOCR/tools/program.py\", line 511, in eval\\n    for idx, batch in enumerate(valid_dataloader):\\n  File \"/usr/local/lib/python3.10/dist-packages/paddle/io/dataloader/dataloader_iter.py\", line 825, in __next__\\n    self._reader.read_next_list()[0]\\nSystemError: (Fatal) Blocking queue is killed because the data reader raises an exception.\\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at ../paddle/fluid/operators/reader/blocking_queue.h:175)\\n\\n\\reval model::   0%|          | 0/32 [00:02<?, ?it/s]\\n'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "class ModelEvaluation:\n",
    "  def __init__(self, model_path, data_test_path, label_test_path):\n",
    "    self.model_path = model_path\n",
    "    self.data_test_path = data_test_path\n",
    "    self.label_test_path = label_test_path\n",
    "\n",
    "  def _run_evaluation(self, command, config):\n",
    "    cmd_string = f\"{command} -c {config} -o Global.checkpoints='{self.model_path}' Eval.dataset.data_dir='{self.data_test_path}' Eval.dataset.label_file_test='{self.label_test_path}'\"\n",
    "    result = subprocess.run(cmd_string, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "      print(\"Model Evaluation Result:\")\n",
    "      print(result.stdout)\n",
    "    else:\n",
    "      print(\"Error in Model Evaluation:\")\n",
    "      print(result.stderr)\n",
    "\n",
    "  def evaluate_detection(self):\n",
    "    command = \"python3 tools/eval.py\"\n",
    "    config = \"configs/det/det_r50_db++_icdar15.yml\"\n",
    "    self._run_evaluation(command, config)\n",
    "\n",
    "  def evaluate_recognition(self):\n",
    "    command = \"python3 tools/eval.py\"\n",
    "    config = \"configs/rec/rec_r50_fpn_srn.yml\"\n",
    "    self._run_evaluation(command, config)\n",
    "\n",
    "\n",
    "# det_model_path = \"./artifacts/model-txx4644w:v6/model_ckpt\"\n",
    "# det_data_test_path = \"./train_data/data_ocr_doc/\"\n",
    "# det_label_test_path = \"./train_data/label_final4eval/det_label_final.txt\"\n",
    "\n",
    "# det_evaluator = ModelEvaluation(det_model_path, det_data_test_path, det_label_test_path)\n",
    "# det_evaluator.evaluate_detection()\n",
    "\n",
    "rec_model_path = \"./output/rec/srn_new/best_accuracy\"\n",
    "rec_data_test_path = \"./train_data/rec_data_final\"\n",
    "rec_label_test_path = \"./train_data/label_final4eval/rec_label_eval.txt\"\n",
    "\n",
    "rec_evaluator = ModelEvaluation(rec_model_path, rec_data_test_path, rec_label_test_path)\n",
    "rec_evaluator.evaluate_recognition()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zs7HFK3Arw8u"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vn_paddleocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
